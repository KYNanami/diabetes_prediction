---
title: "R Notebook"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 

```{r}

install.packages("fastmap")
packageVersion("fastmap")
install.packages("agricolae")
```

```{r}
library(agricolae)
library(forcats)
library(leaps)
library(bestglm)
library(regclass)
set.seed(537)



## Data cleanup
diab <- read.csv("diabetes_prediction_dataset.csv")
diab <- na.omit(diab)
diab <- unique(diab)
diab <- diab[diab$smoking_history != "No Info", ]
diab <- diab[diab$smoking_history != "ever", ]

# Factorize categorical covariates
diab$gender <- as.factor(diab$gender)
diab$hypertension <- as.factor(diab$hypertension)
diab$heart_disease <- as.factor(diab$heart_disease)
diab$smoking_history <- as.factor(diab$smoking_history)
diab$blood_glucose_level <- as.numeric(diab$blood_glucose_level)
diab$diabetes <- as.factor(diab$diabetes)
summary(diab)

# Remove gender == "Other" because they account for ~0.02% of the data
diab <- diab[-which(diab$gender == "Other"),]
diab$gender <- droplevels(diab$gender)

## 20/80 test/train split; sampled from each diabetes category because data is unbalanced
diab <- diab[order(diab$diabetes, decreasing=TRUE),]
diabetes_count <- length(which(diab$diabetes == 1))
no_diabetes_count <- length(which(diab$diabetes == 0))
diabetes_test <- sample(1:diabetes_count, ceiling(diabetes_count*0.2))
no_diabetes_test <- sample((diabetes_count+1):nrow(diab), ceiling(no_diabetes_count*0.2))
diab_test <- diab[c(diabetes_test, no_diabetes_test),]
diab_train <- diab[-c(diabetes_test, no_diabetes_test),]
summary(diab_train)

## Try PCA on numerical covariates
diab_train_num <- diab_train[,c(2,6,7,8)]
diab_train_num <- as.matrix(diab_train_num)
for (i in 1:4) {
  diab_train_num[,i] <- scale(diab_train_num[,i])
}
pca <- eigen(t(diab_train_num)%*%diab_train_num)
pca$values
critical <- pca$values[1]/pca$values
critical # No concerningly large critical values
```


```{r, echo=TRUE}
## Try initial logistic model
M0 <- glm(diabetes~., data=diab_train, family=binomial(link="logit"))
summary(M0)
# confusion_matrix(M0)

## Use Tukey's test on smoking_history to see factor level relationships; try merging level pairs with highest p-value, one at a time
#Tukey0 <- HSD.test(M0, "smoking_history", group=FALSE)
#Tukey0

#diab_train$smoking_history <- fct_collapse(diab_train$smoking_history, cur_not = c("current", "not current"))
#M1 <- glm(diabetes~., data=diab_train, family=binomial(link="logit"))
#Tukey1 <- HSD.test(M1, "smoking_history", group=FALSE)
#Tukey1

#diab_train$smoking_history <- fct_collapse(diab_train$smoking_history, cur_not_ever = c("cur_not", "ever"))
#M2 <- glm(diabetes~., data=diab_train, family=binomial(link="logit"))
#Tukey2 <- HSD.test(M2, "smoking_history", group=FALSE)
#Tukey2

# Looks better, although whether or not combining "current", "not current", and "ever" together makes sense is up for debate; if needed we can revert back to M0 or M1
#M <- M2

## Check for multicolinearity
#VIF(M)

## See how the model works on test data, just for fun
#diab_test$smoking_history <- fct_collapse(diab_test$smoking_history, cur_not = c("current", "not current"))
#diab_test$smoking_history <- fct_collapse(diab_test$smoking_history, cur_not_ever = c("cur_not", "ever"))
#confusion_matrix(M, DATA=diab_test)

```


```{r, echo=TRUE}

# Combine not current and former
diab_train$smoking_history <- fct_collapse(diab_train$smoking_history, cur_not = c("not current", "former"))

# Factorize categorical covariates
#diab$gender <- as.factor(diab$gender)
#diab$hypertension <- as.factor(diab$hypertension)
#diab$heart_disease <- as.factor(diab$heart_disease)
#diab$smoking_history <- as.factor(diab$smoking_history)
#diab$blood_glucose_level <- as.numeric(diab$blood_glucose_level)
#summary(diab)

model_2 = glm(diabetes~., data = diab_train, family=binomial(link="logit"))
summary(model_2)
```

```{r, echo=TRUE}
# Try dropping smoking_history
diab_train_new <- diab_train[,-5]
model_3 <- glm(diabetes~., data=diab_train_new, family=binomial(link="logit"))
summary(model_3)
anova(model_3, model_2, test="Chisq")
# Reject model_2 and drop smoking_history
```

```{r}
install.packages("ROCR")
```
```{r}
install.packages("ggplot2")
```

```{r}
# Predict probabilities on the test data for model_3
probabilities <- predict(model_3, newdata = diab_train, type = "response")

# Initialize vectors to store metrics
accuracy <- c()
precision <- c()
recall <- c()
thresholds <- seq(0, 1, by = 0.05)

for (threshold in thresholds) {
  # Make predictions based on the threshold
  predicted_outcomes <- ifelse(probabilities > threshold, 1, 0)

  # Calculate TP, FP, FN, TN
  TP <- sum(predicted_outcomes == 1 & diab_train$diabetes == 1)
  FP <- sum(predicted_outcomes == 1 & diab_train$diabetes == 0)
  FN <- sum(predicted_outcomes == 0 & diab_train$diabetes == 1)
  TN <- sum(predicted_outcomes == 0 & diab_train$diabetes == 0)

  # Calculate metrics
  acc <- (TP + TN) / (TP + FP + FN + TN)
  prec <- ifelse(TP + FP == 0, 0, TP / (TP + FP))
  rec <- ifelse(TP + FN == 0, 0, TP / (TP + FN))

  # Store the metrics
  accuracy <- c(accuracy, acc)
  precision <- c(precision, prec)
  recall <- c(recall, rec)
}

# Create a data frame for the results
results_df <- data.frame(Threshold = thresholds, Accuracy = accuracy, Precision = precision, Recall = recall)

# Print the data frame
print(results_df)

# Generate a line graph
plot(results_df$Threshold, results_df$Accuracy, type = "l", col = "green", ylim = range(0, 1),
     xlab = "Threshold", ylab = "Metric Value", main = "Model Metrics by Threshold on Training Data")
lines(results_df$Threshold, results_df$Precision, col = "blue")
lines(results_df$Threshold, results_df$Recall, col = "red")
legend("bottomright", legend = c("Accuracy", "Precision", "Recall"), col = c("green", "blue", "red"), lty = 1)



```








```{r}
# Predict probabilities on the test data for model_3
probabilities <- predict(model_3, newdata = diab_train, type = "response")

# Initialize vectors to store FP and FN rates
fp_rates <- c()
fn_rates <- c()
thresholds <- seq(0, 1, by = 0.05)  # Adjust the step size as needed

# Total actual positives and negatives
total_positives <- sum(diab_train$diabetes == 1)
total_negatives <- sum(diab_train$diabetes == 0)

for (threshold in thresholds) {
  # Make predictions based on the threshold
  predicted_outcomes <- ifelse(probabilities > threshold, 1, 0)
  
  # Calculate FP and FN
  fp <- sum(predicted_outcomes == 1 & diab_train$diabetes == 0)
  fn <- sum(predicted_outcomes == 0 & diab_train$diabetes == 1)

  # Calculate and store the rates
  fp_rate <- fp / total_negatives
  fn_rate <- fn / total_positives
  fp_rates <- c(fp_rates, fp_rate)
  fn_rates <- c(fn_rates, fn_rate)
}

# Plotting
plot(thresholds, fp_rates, type = "l", col = "blue", ylim = c(0, max(c(fp_rates, fn_rates))),
     xlab = "Threshold", ylab = "Rate", main = "False Negative and False Positive Trade-off by Threshold on Train Data", 
     xaxt = 'n', yaxt = 'n')
axis(1, at = seq(0, 1, by = 0.05))
axis(2, at = seq(0, max(c(fp_rates, fn_rates)), by = 0.1))
lines(thresholds, fn_rates, type = "l", col = "red")
legend("topright", legend = c("False Positive Rate", "False Negative Rate"), col = c("blue", "red"), lty = 1)


```


```{r}

# Predict probabilities on the test data for model_3
probabilities <- predict(model_3, newdata = diab_test, type = "response")

# Initialize vectors to store metrics
accuracy <- c()
precision <- c()
recall <- c()
thresholds <- seq(0, 1, by = 0.05)

for (threshold in thresholds) {
  # Make predictions based on the threshold
  predicted_outcomes <- ifelse(probabilities > threshold, 1, 0)

  # Calculate TP, FP, FN, TN
  TP <- sum(predicted_outcomes == 1 & diab_test$diabetes == 1)
  FP <- sum(predicted_outcomes == 1 & diab_test$diabetes == 0)
  FN <- sum(predicted_outcomes == 0 & diab_test$diabetes == 1)
  TN <- sum(predicted_outcomes == 0 & diab_test$diabetes == 0)

  # Calculate metrics
  acc <- (TP + TN) / (TP + FP + FN + TN)
  prec <- ifelse(TP + FP == 0, 0, TP / (TP + FP))
  rec <- ifelse(TP + FN == 0, 0, TP / (TP + FN))

  # Store the metrics
  accuracy <- c(accuracy, acc)
  precision <- c(precision, prec)
  recall <- c(recall, rec)
}

# Create a data frame for the results
results_df <- data.frame(Threshold = thresholds, Accuracy = accuracy, Precision = precision, Recall = recall)

# Print the data frame
print(results_df)

# Generate a line graph
plot(results_df$Threshold, results_df$Accuracy, type = "l", col = "green", ylim = range(0, 1),
     xlab = "Threshold", ylab = "Metric Value", main = "Model Metrics by Threshold on Test Data")
lines(results_df$Threshold, results_df$Precision, col = "blue")
lines(results_df$Threshold, results_df$Recall, col = "red")
legend("bottomright", legend = c("Accuracy", "Precision", "Recall"), col = c("green", "blue", "red"), lty = 1)


```

```{r}
# Predict probabilities on the test data for model_3
probabilities <- predict(model_3, newdata = diab_test, type = "response")

# Initialize vectors to store FP and FN rates
fp_rates <- c()
fn_rates <- c()
thresholds <- seq(0, 1, by = 0.05)  # Adjust the step size as needed

# Total actual positives and negatives
total_positives <- sum(diab_test$diabetes == 1)
total_negatives <- sum(diab_test$diabetes == 0)

for (threshold in thresholds) {
  # Make predictions based on the threshold
  predicted_outcomes <- ifelse(probabilities > threshold, 1, 0)
  
  # Calculate FP and FN
  fp <- sum(predicted_outcomes == 1 & diab_test$diabetes == 0)
  fn <- sum(predicted_outcomes == 0 & diab_test$diabetes == 1)

  # Calculate and store the rates
  fp_rate <- fp / total_negatives
  fn_rate <- fn / total_positives
  fp_rates <- c(fp_rates, fp_rate)
  fn_rates <- c(fn_rates, fn_rate)
}

# Plotting
plot(thresholds, fp_rates, type = "l", col = "blue", ylim = c(0, max(c(fp_rates, fn_rates))),
     xlab = "Threshold", ylab = "Rate", main = "False Negative and False Positive Trade-off by Threshold on Test Data", 
     xaxt = 'n', yaxt = 'n')
axis(1, at = seq(0, 1, by = 0.05))
axis(2, at = seq(0, max(c(fp_rates, fn_rates)), by = 0.1))
lines(thresholds, fn_rates, type = "l", col = "red")
legend("topright", legend = c("False Positive Rate", "False Negative Rate"), col = c("blue", "red"), lty = 1)


```
Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.

```

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.
